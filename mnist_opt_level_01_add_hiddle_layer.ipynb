{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"emnist_opt_level_01_add_hiddle_layer.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOi/9Su5hqOJ1/lvZyfnS44"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"CLiJzZJNsPOB","executionInfo":{"status":"ok","timestamp":1606010148409,"user_tz":-540,"elapsed":2507,"user":{"displayName":"박문기(Russell)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizQo6to0OvUtiNQKTVjXpjpc2acrkjL0QP6_B-=s64","userId":"17970950316440342447"}}},"source":["import tensorflow as tf\n","import numpy as np\n","from tensorflow import keras"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZmA6HYaoseKM","executionInfo":{"status":"ok","timestamp":1606010148439,"user_tz":-540,"elapsed":2524,"user":{"displayName":"박문기(Russell)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizQo6to0OvUtiNQKTVjXpjpc2acrkjL0QP6_B-=s64","userId":"17970950316440342447"}}},"source":["#하이퍼 파라메터 정의(매개변수들)\n","EPOCHS = 200\n","BATCH_SIZE = 128\n","VERBOSE = 1\n","NB_CLASSES = 10 #출력갯수 = 숫자의 갯수\n","N_HIDDEN = 128 \n","VALIDATION_SPLIT = 0.2 #검증을 위해 남겨둘 훈련 데이타"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6a_uWCrqtEIJ","executionInfo":{"status":"ok","timestamp":1606010149187,"user_tz":-540,"elapsed":3256,"user":{"displayName":"박문기(Russell)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizQo6to0OvUtiNQKTVjXpjpc2acrkjL0QP6_B-=s64","userId":"17970950316440342447"}},"outputId":"32071d0e-5912-4727-af97-2ab3aa9dc598"},"source":["# MNIST 데이타셋 로드(MNIST는 숫자만, eMNIST는 숫자+알파벳, 패션MNIST는 옷그림들이 있다)\n","# X값 훈련용, 테스트 데이터를 각각 60,000개와 10,000개로 나눈다\n","# 레이블(정답, Y값)에 대한 원핫 인코딩을 자동으로 적용한다\n","# 아래 데이타셋을 .png 형태의 이미지를 이미 숫자화한 배열형태로 바꾸어 놓은 것이며, .csv형태가 분석 초기 데이타이다.\n","mnist = keras.datasets.mnist\n","(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n","\n","# X_train은 60,000개 행으로 28x28 값을 가진다. 이를 60,000 x 784(28x28)의 행렬형태로 변환한다.\n","RESHAPED = 784\n","\n","X_train = X_train.reshape(60000, RESHAPED)\n","X_test = X_test.reshape(10000, RESHAPED)\n","\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","\n","# 입력을 [0, 1] 사이로 정규화\n","X_train /= 255.0\n","X_train /= 255.0\n","\n","print(X_train.shape[0], 'train samples')\n","print(X_test.shape[0], 'train samples')\n","\n","# 레이블을 원한 엔코딩, 그래야 행렬 연산이 가능함\n","Y_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES)\n","Y_test = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","60000 train samples\n","10000 train samples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yLoTJoMXvC4S","executionInfo":{"status":"ok","timestamp":1606010149188,"user_tz":-540,"elapsed":3254,"user":{"displayName":"박문기(Russell)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizQo6to0OvUtiNQKTVjXpjpc2acrkjL0QP6_B-=s64","userId":"17970950316440342447"}}},"source":["# 모델 구축(정의)\n","model = tf.keras.models.Sequential()\n","model.add(keras.layers.Dense(N_HIDDEN, input_shape=(RESHAPED,), name='input_Dense_layer_1', activation='relu'))\n","model.add(keras.layers.Dense(N_HIDDEN, name='hidden_Dense_layer_2', activation='relu'))\n","model.add(keras.layers.Dense(NB_CLASSES, name='output_Dense_layer_3', activation='softmax'))"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"rfRXM9Nhw5Kt","executionInfo":{"status":"ok","timestamp":1606010149188,"user_tz":-540,"elapsed":3251,"user":{"displayName":"박문기(Russell)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizQo6to0OvUtiNQKTVjXpjpc2acrkjL0QP6_B-=s64","userId":"17970950316440342447"}}},"source":["# 모델 컴파일\n","model.compile(optimizer='SGD',\n","             loss='categorical_crossentropy',\n","             metrics=['accuracy'])"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RsSr7R9RzMFm","executionInfo":{"status":"ok","timestamp":1606010149189,"user_tz":-540,"elapsed":3237,"user":{"displayName":"박문기(Russell)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizQo6to0OvUtiNQKTVjXpjpc2acrkjL0QP6_B-=s64","userId":"17970950316440342447"}},"outputId":"ed223af0-14e0-4ceb-e071-13b83181dab0"},"source":["# 모델 형태 보기\n","model.summary()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_Dense_layer_1 (Dense)  (None, 128)               100480    \n","_________________________________________________________________\n","hidden_Dense_layer_2 (Dense) (None, 128)               16512     \n","_________________________________________________________________\n","output_Dense_layer_3 (Dense) (None, 10)                1290      \n","=================================================================\n","Total params: 118,282\n","Trainable params: 118,282\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ru4BliBKxrkG","executionInfo":{"status":"ok","timestamp":1606010439950,"user_tz":-540,"elapsed":293989,"user":{"displayName":"박문기(Russell)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizQo6to0OvUtiNQKTVjXpjpc2acrkjL0QP6_B-=s64","userId":"17970950316440342447"}},"outputId":"f741dc69-f5f7-4afa-b9d8-1d1b3b38ce7d"},"source":["# 모델 훈련\n","model.fit(x = X_train, y = Y_train, \n","          batch_size = BATCH_SIZE, epochs=EPOCHS,\n","          verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Epoch 1/200\n","375/375 [==============================] - 2s 4ms/step - loss: 2.3006 - accuracy: 0.1144 - val_loss: 2.3004 - val_accuracy: 0.1060\n","Epoch 2/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2997 - accuracy: 0.1140 - val_loss: 2.3003 - val_accuracy: 0.1060\n","Epoch 3/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2994 - accuracy: 0.1140 - val_loss: 2.3002 - val_accuracy: 0.1060\n","Epoch 4/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2993 - accuracy: 0.1140 - val_loss: 2.3002 - val_accuracy: 0.1060\n","Epoch 5/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2992 - accuracy: 0.1140 - val_loss: 2.3002 - val_accuracy: 0.1060\n","Epoch 6/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2991 - accuracy: 0.1140 - val_loss: 2.3002 - val_accuracy: 0.1060\n","Epoch 7/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2991 - accuracy: 0.1140 - val_loss: 2.3001 - val_accuracy: 0.1060\n","Epoch 8/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2990 - accuracy: 0.1140 - val_loss: 2.3000 - val_accuracy: 0.1060\n","Epoch 9/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2989 - accuracy: 0.1140 - val_loss: 2.2999 - val_accuracy: 0.1060\n","Epoch 10/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2989 - accuracy: 0.1140 - val_loss: 2.2998 - val_accuracy: 0.1060\n","Epoch 11/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2988 - accuracy: 0.1140 - val_loss: 2.2998 - val_accuracy: 0.1060\n","Epoch 12/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2987 - accuracy: 0.1140 - val_loss: 2.2997 - val_accuracy: 0.1060\n","Epoch 13/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2986 - accuracy: 0.1140 - val_loss: 2.2996 - val_accuracy: 0.1060\n","Epoch 14/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2986 - accuracy: 0.1140 - val_loss: 2.2995 - val_accuracy: 0.1060\n","Epoch 15/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2985 - accuracy: 0.1140 - val_loss: 2.2995 - val_accuracy: 0.1060\n","Epoch 16/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2984 - accuracy: 0.1140 - val_loss: 2.2994 - val_accuracy: 0.1060\n","Epoch 17/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2983 - accuracy: 0.1140 - val_loss: 2.2993 - val_accuracy: 0.1060\n","Epoch 18/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2982 - accuracy: 0.1140 - val_loss: 2.2992 - val_accuracy: 0.1060\n","Epoch 19/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2981 - accuracy: 0.1140 - val_loss: 2.2991 - val_accuracy: 0.1060\n","Epoch 20/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2981 - accuracy: 0.1140 - val_loss: 2.2991 - val_accuracy: 0.1060\n","Epoch 21/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2980 - accuracy: 0.1140 - val_loss: 2.2990 - val_accuracy: 0.1060\n","Epoch 22/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2979 - accuracy: 0.1140 - val_loss: 2.2989 - val_accuracy: 0.1060\n","Epoch 23/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2978 - accuracy: 0.1140 - val_loss: 2.2987 - val_accuracy: 0.1060\n","Epoch 24/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2977 - accuracy: 0.1140 - val_loss: 2.2987 - val_accuracy: 0.1060\n","Epoch 25/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2976 - accuracy: 0.1140 - val_loss: 2.2985 - val_accuracy: 0.1060\n","Epoch 26/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2975 - accuracy: 0.1140 - val_loss: 2.2984 - val_accuracy: 0.1060\n","Epoch 27/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2974 - accuracy: 0.1140 - val_loss: 2.2983 - val_accuracy: 0.1060\n","Epoch 28/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2973 - accuracy: 0.1140 - val_loss: 2.2982 - val_accuracy: 0.1060\n","Epoch 29/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2972 - accuracy: 0.1140 - val_loss: 2.2981 - val_accuracy: 0.1060\n","Epoch 30/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2970 - accuracy: 0.1140 - val_loss: 2.2980 - val_accuracy: 0.1060\n","Epoch 31/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2970 - accuracy: 0.1140 - val_loss: 2.2978 - val_accuracy: 0.1060\n","Epoch 32/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2968 - accuracy: 0.1140 - val_loss: 2.2978 - val_accuracy: 0.1060\n","Epoch 33/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2967 - accuracy: 0.1140 - val_loss: 2.2976 - val_accuracy: 0.1060\n","Epoch 34/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2966 - accuracy: 0.1140 - val_loss: 2.2975 - val_accuracy: 0.1060\n","Epoch 35/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2965 - accuracy: 0.1140 - val_loss: 2.2974 - val_accuracy: 0.1060\n","Epoch 36/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2964 - accuracy: 0.1140 - val_loss: 2.2973 - val_accuracy: 0.1060\n","Epoch 37/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2962 - accuracy: 0.1140 - val_loss: 2.2972 - val_accuracy: 0.1060\n","Epoch 38/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2961 - accuracy: 0.1140 - val_loss: 2.2970 - val_accuracy: 0.1060\n","Epoch 39/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2960 - accuracy: 0.1140 - val_loss: 2.2969 - val_accuracy: 0.1060\n","Epoch 40/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2959 - accuracy: 0.1140 - val_loss: 2.2967 - val_accuracy: 0.1060\n","Epoch 41/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2957 - accuracy: 0.1140 - val_loss: 2.2966 - val_accuracy: 0.1060\n","Epoch 42/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2955 - accuracy: 0.1140 - val_loss: 2.2965 - val_accuracy: 0.1060\n","Epoch 43/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2954 - accuracy: 0.1140 - val_loss: 2.2963 - val_accuracy: 0.1060\n","Epoch 44/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2953 - accuracy: 0.1140 - val_loss: 2.2961 - val_accuracy: 0.1060\n","Epoch 45/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2951 - accuracy: 0.1140 - val_loss: 2.2960 - val_accuracy: 0.1060\n","Epoch 46/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2949 - accuracy: 0.1140 - val_loss: 2.2959 - val_accuracy: 0.1060\n","Epoch 47/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2948 - accuracy: 0.1140 - val_loss: 2.2956 - val_accuracy: 0.1060\n","Epoch 48/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2946 - accuracy: 0.1140 - val_loss: 2.2955 - val_accuracy: 0.1060\n","Epoch 49/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2945 - accuracy: 0.1140 - val_loss: 2.2953 - val_accuracy: 0.1060\n","Epoch 50/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2942 - accuracy: 0.1140 - val_loss: 2.2952 - val_accuracy: 0.1060\n","Epoch 51/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2941 - accuracy: 0.1140 - val_loss: 2.2949 - val_accuracy: 0.1060\n","Epoch 52/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2939 - accuracy: 0.1140 - val_loss: 2.2947 - val_accuracy: 0.1060\n","Epoch 53/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2937 - accuracy: 0.1140 - val_loss: 2.2945 - val_accuracy: 0.1060\n","Epoch 54/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2935 - accuracy: 0.1140 - val_loss: 2.2943 - val_accuracy: 0.1060\n","Epoch 55/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2933 - accuracy: 0.1140 - val_loss: 2.2941 - val_accuracy: 0.1060\n","Epoch 56/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2931 - accuracy: 0.1140 - val_loss: 2.2939 - val_accuracy: 0.1060\n","Epoch 57/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2929 - accuracy: 0.1140 - val_loss: 2.2937 - val_accuracy: 0.1060\n","Epoch 58/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2927 - accuracy: 0.1140 - val_loss: 2.2935 - val_accuracy: 0.1060\n","Epoch 59/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2924 - accuracy: 0.1140 - val_loss: 2.2933 - val_accuracy: 0.1060\n","Epoch 60/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2922 - accuracy: 0.1140 - val_loss: 2.2930 - val_accuracy: 0.1060\n","Epoch 61/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2920 - accuracy: 0.1140 - val_loss: 2.2927 - val_accuracy: 0.1060\n","Epoch 62/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2917 - accuracy: 0.1140 - val_loss: 2.2925 - val_accuracy: 0.1060\n","Epoch 63/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2914 - accuracy: 0.1140 - val_loss: 2.2922 - val_accuracy: 0.1060\n","Epoch 64/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2912 - accuracy: 0.1140 - val_loss: 2.2920 - val_accuracy: 0.1060\n","Epoch 65/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2909 - accuracy: 0.1140 - val_loss: 2.2917 - val_accuracy: 0.1060\n","Epoch 66/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2906 - accuracy: 0.1140 - val_loss: 2.2913 - val_accuracy: 0.1060\n","Epoch 67/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2903 - accuracy: 0.1140 - val_loss: 2.2911 - val_accuracy: 0.1060\n","Epoch 68/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2900 - accuracy: 0.1140 - val_loss: 2.2908 - val_accuracy: 0.1060\n","Epoch 69/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2897 - accuracy: 0.1140 - val_loss: 2.2904 - val_accuracy: 0.1060\n","Epoch 70/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2894 - accuracy: 0.1140 - val_loss: 2.2901 - val_accuracy: 0.1060\n","Epoch 71/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2890 - accuracy: 0.1140 - val_loss: 2.2897 - val_accuracy: 0.1060\n","Epoch 72/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2887 - accuracy: 0.1140 - val_loss: 2.2894 - val_accuracy: 0.1060\n","Epoch 73/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2883 - accuracy: 0.1140 - val_loss: 2.2889 - val_accuracy: 0.1060\n","Epoch 74/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2880 - accuracy: 0.1140 - val_loss: 2.2886 - val_accuracy: 0.1060\n","Epoch 75/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2876 - accuracy: 0.1140 - val_loss: 2.2882 - val_accuracy: 0.1060\n","Epoch 76/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2872 - accuracy: 0.1140 - val_loss: 2.2878 - val_accuracy: 0.1060\n","Epoch 77/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2867 - accuracy: 0.1140 - val_loss: 2.2873 - val_accuracy: 0.1060\n","Epoch 78/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2863 - accuracy: 0.1141 - val_loss: 2.2867 - val_accuracy: 0.1060\n","Epoch 79/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2858 - accuracy: 0.1142 - val_loss: 2.2864 - val_accuracy: 0.1060\n","Epoch 80/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2854 - accuracy: 0.1140 - val_loss: 2.2859 - val_accuracy: 0.1060\n","Epoch 81/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2849 - accuracy: 0.1144 - val_loss: 2.2854 - val_accuracy: 0.1062\n","Epoch 82/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2843 - accuracy: 0.1149 - val_loss: 2.2848 - val_accuracy: 0.1195\n","Epoch 83/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2838 - accuracy: 0.1155 - val_loss: 2.2844 - val_accuracy: 0.1062\n","Epoch 84/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2833 - accuracy: 0.1148 - val_loss: 2.2837 - val_accuracy: 0.1086\n","Epoch 85/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2827 - accuracy: 0.1161 - val_loss: 2.2831 - val_accuracy: 0.1167\n","Epoch 86/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2821 - accuracy: 0.1184 - val_loss: 2.2825 - val_accuracy: 0.1192\n","Epoch 87/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2814 - accuracy: 0.1184 - val_loss: 2.2818 - val_accuracy: 0.1471\n","Epoch 88/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2807 - accuracy: 0.1314 - val_loss: 2.2813 - val_accuracy: 0.1080\n","Epoch 89/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2801 - accuracy: 0.1259 - val_loss: 2.2804 - val_accuracy: 0.1104\n","Epoch 90/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2794 - accuracy: 0.1282 - val_loss: 2.2797 - val_accuracy: 0.1103\n","Epoch 91/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2786 - accuracy: 0.1330 - val_loss: 2.2790 - val_accuracy: 0.1126\n","Epoch 92/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2778 - accuracy: 0.1339 - val_loss: 2.2782 - val_accuracy: 0.1128\n","Epoch 93/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2770 - accuracy: 0.1334 - val_loss: 2.2773 - val_accuracy: 0.1436\n","Epoch 94/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2761 - accuracy: 0.1469 - val_loss: 2.2764 - val_accuracy: 0.1157\n","Epoch 95/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2752 - accuracy: 0.1431 - val_loss: 2.2754 - val_accuracy: 0.1423\n","Epoch 96/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2742 - accuracy: 0.1506 - val_loss: 2.2744 - val_accuracy: 0.1479\n","Epoch 97/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2732 - accuracy: 0.1519 - val_loss: 2.2732 - val_accuracy: 0.1744\n","Epoch 98/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2721 - accuracy: 0.1630 - val_loss: 2.2722 - val_accuracy: 0.1467\n","Epoch 99/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2710 - accuracy: 0.1660 - val_loss: 2.2711 - val_accuracy: 0.1486\n","Epoch 100/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2697 - accuracy: 0.1573 - val_loss: 2.2698 - val_accuracy: 0.2217\n","Epoch 101/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2686 - accuracy: 0.1811 - val_loss: 2.2686 - val_accuracy: 0.1703\n","Epoch 102/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2672 - accuracy: 0.1768 - val_loss: 2.2674 - val_accuracy: 0.1733\n","Epoch 103/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2659 - accuracy: 0.1811 - val_loss: 2.2656 - val_accuracy: 0.1973\n","Epoch 104/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2643 - accuracy: 0.1912 - val_loss: 2.2642 - val_accuracy: 0.1885\n","Epoch 105/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2628 - accuracy: 0.1852 - val_loss: 2.2624 - val_accuracy: 0.2393\n","Epoch 106/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2612 - accuracy: 0.2024 - val_loss: 2.2610 - val_accuracy: 0.1742\n","Epoch 107/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2595 - accuracy: 0.1968 - val_loss: 2.2590 - val_accuracy: 0.1928\n","Epoch 108/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2576 - accuracy: 0.2087 - val_loss: 2.2572 - val_accuracy: 0.1914\n","Epoch 109/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2556 - accuracy: 0.2113 - val_loss: 2.2553 - val_accuracy: 0.1829\n","Epoch 110/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2536 - accuracy: 0.2082 - val_loss: 2.2528 - val_accuracy: 0.2306\n","Epoch 111/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2513 - accuracy: 0.2212 - val_loss: 2.2506 - val_accuracy: 0.2422\n","Epoch 112/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2489 - accuracy: 0.2242 - val_loss: 2.2481 - val_accuracy: 0.2276\n","Epoch 113/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2465 - accuracy: 0.2306 - val_loss: 2.2462 - val_accuracy: 0.1832\n","Epoch 114/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2438 - accuracy: 0.2405 - val_loss: 2.2428 - val_accuracy: 0.2269\n","Epoch 115/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2410 - accuracy: 0.2349 - val_loss: 2.2399 - val_accuracy: 0.2465\n","Epoch 116/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2379 - accuracy: 0.2445 - val_loss: 2.2366 - val_accuracy: 0.2533\n","Epoch 117/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2347 - accuracy: 0.2457 - val_loss: 2.2336 - val_accuracy: 0.2570\n","Epoch 118/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2311 - accuracy: 0.2566 - val_loss: 2.2307 - val_accuracy: 0.1914\n","Epoch 119/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2275 - accuracy: 0.2554 - val_loss: 2.2268 - val_accuracy: 0.1973\n","Epoch 120/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2235 - accuracy: 0.2493 - val_loss: 2.2217 - val_accuracy: 0.2970\n","Epoch 121/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2193 - accuracy: 0.2659 - val_loss: 2.2176 - val_accuracy: 0.2413\n","Epoch 122/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2147 - accuracy: 0.2648 - val_loss: 2.2127 - val_accuracy: 0.2461\n","Epoch 123/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2098 - accuracy: 0.2686 - val_loss: 2.2075 - val_accuracy: 0.2594\n","Epoch 124/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.2048 - accuracy: 0.2665 - val_loss: 2.2020 - val_accuracy: 0.3067\n","Epoch 125/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.1991 - accuracy: 0.2804 - val_loss: 2.1963 - val_accuracy: 0.2619\n","Epoch 126/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.1930 - accuracy: 0.2799 - val_loss: 2.1905 - val_accuracy: 0.2729\n","Epoch 127/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.1867 - accuracy: 0.2777 - val_loss: 2.1831 - val_accuracy: 0.3030\n","Epoch 128/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.1798 - accuracy: 0.2896 - val_loss: 2.1763 - val_accuracy: 0.2567\n","Epoch 129/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.1724 - accuracy: 0.2848 - val_loss: 2.1689 - val_accuracy: 0.2808\n","Epoch 130/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.1643 - accuracy: 0.2899 - val_loss: 2.1604 - val_accuracy: 0.2938\n","Epoch 131/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.1559 - accuracy: 0.2902 - val_loss: 2.1532 - val_accuracy: 0.2697\n","Epoch 132/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.1470 - accuracy: 0.2971 - val_loss: 2.1423 - val_accuracy: 0.2884\n","Epoch 133/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.1371 - accuracy: 0.2999 - val_loss: 2.1325 - val_accuracy: 0.2928\n","Epoch 134/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.1271 - accuracy: 0.3043 - val_loss: 2.1218 - val_accuracy: 0.2828\n","Epoch 135/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.1161 - accuracy: 0.3041 - val_loss: 2.1099 - val_accuracy: 0.3372\n","Epoch 136/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.1044 - accuracy: 0.3156 - val_loss: 2.0975 - val_accuracy: 0.3192\n","Epoch 137/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.0921 - accuracy: 0.3137 - val_loss: 2.0851 - val_accuracy: 0.3267\n","Epoch 138/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.0794 - accuracy: 0.3210 - val_loss: 2.0726 - val_accuracy: 0.3055\n","Epoch 139/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.0660 - accuracy: 0.3241 - val_loss: 2.0576 - val_accuracy: 0.3442\n","Epoch 140/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.0521 - accuracy: 0.3279 - val_loss: 2.0432 - val_accuracy: 0.3517\n","Epoch 141/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.0372 - accuracy: 0.3347 - val_loss: 2.0279 - val_accuracy: 0.3638\n","Epoch 142/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.0218 - accuracy: 0.3400 - val_loss: 2.0122 - val_accuracy: 0.3647\n","Epoch 143/200\n","375/375 [==============================] - 1s 4ms/step - loss: 2.0063 - accuracy: 0.3468 - val_loss: 1.9965 - val_accuracy: 0.3527\n","Epoch 144/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.9902 - accuracy: 0.3499 - val_loss: 1.9805 - val_accuracy: 0.3647\n","Epoch 145/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.9738 - accuracy: 0.3582 - val_loss: 1.9658 - val_accuracy: 0.3412\n","Epoch 146/200\n","375/375 [==============================] - 2s 4ms/step - loss: 1.9573 - accuracy: 0.3591 - val_loss: 1.9455 - val_accuracy: 0.3833\n","Epoch 147/200\n","375/375 [==============================] - 2s 4ms/step - loss: 1.9403 - accuracy: 0.3636 - val_loss: 1.9274 - val_accuracy: 0.3945\n","Epoch 148/200\n","375/375 [==============================] - 2s 4ms/step - loss: 1.9224 - accuracy: 0.3746 - val_loss: 1.9109 - val_accuracy: 0.3733\n","Epoch 149/200\n","375/375 [==============================] - 2s 4ms/step - loss: 1.9049 - accuracy: 0.3745 - val_loss: 1.8913 - val_accuracy: 0.4001\n","Epoch 150/200\n","375/375 [==============================] - 2s 5ms/step - loss: 1.8873 - accuracy: 0.3821 - val_loss: 1.8784 - val_accuracy: 0.3828\n","Epoch 151/200\n","375/375 [==============================] - 2s 5ms/step - loss: 1.8693 - accuracy: 0.3904 - val_loss: 1.8595 - val_accuracy: 0.3890\n","Epoch 152/200\n","375/375 [==============================] - 2s 4ms/step - loss: 1.8515 - accuracy: 0.3932 - val_loss: 1.8375 - val_accuracy: 0.4042\n","Epoch 153/200\n","375/375 [==============================] - 2s 4ms/step - loss: 1.8340 - accuracy: 0.3965 - val_loss: 1.8189 - val_accuracy: 0.4068\n","Epoch 154/200\n","375/375 [==============================] - 2s 6ms/step - loss: 1.8155 - accuracy: 0.4066 - val_loss: 1.8031 - val_accuracy: 0.4068\n","Epoch 155/200\n","375/375 [==============================] - 2s 6ms/step - loss: 1.7970 - accuracy: 0.4092 - val_loss: 1.7801 - val_accuracy: 0.4158\n","Epoch 156/200\n","375/375 [==============================] - 2s 5ms/step - loss: 1.7791 - accuracy: 0.4111 - val_loss: 1.7669 - val_accuracy: 0.4135\n","Epoch 157/200\n","375/375 [==============================] - 2s 5ms/step - loss: 1.7608 - accuracy: 0.4158 - val_loss: 1.7462 - val_accuracy: 0.4304\n","Epoch 158/200\n","375/375 [==============================] - 2s 4ms/step - loss: 1.7451 - accuracy: 0.4184 - val_loss: 1.7276 - val_accuracy: 0.4441\n","Epoch 159/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.7269 - accuracy: 0.4272 - val_loss: 1.7181 - val_accuracy: 0.4418\n","Epoch 160/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.7095 - accuracy: 0.4269 - val_loss: 1.7053 - val_accuracy: 0.4192\n","Epoch 161/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.6922 - accuracy: 0.4328 - val_loss: 1.6699 - val_accuracy: 0.4437\n","Epoch 162/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.6745 - accuracy: 0.4380 - val_loss: 1.6562 - val_accuracy: 0.4316\n","Epoch 163/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.6581 - accuracy: 0.4360 - val_loss: 1.6698 - val_accuracy: 0.4527\n","Epoch 164/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.6424 - accuracy: 0.4439 - val_loss: 1.6156 - val_accuracy: 0.4456\n","Epoch 165/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.6274 - accuracy: 0.4432 - val_loss: 1.6039 - val_accuracy: 0.4423\n","Epoch 166/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.6119 - accuracy: 0.4438 - val_loss: 1.5822 - val_accuracy: 0.4642\n","Epoch 167/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.5960 - accuracy: 0.4488 - val_loss: 1.5774 - val_accuracy: 0.4891\n","Epoch 168/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.5837 - accuracy: 0.4537 - val_loss: 1.5573 - val_accuracy: 0.4764\n","Epoch 169/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.5639 - accuracy: 0.4575 - val_loss: 1.5542 - val_accuracy: 0.4406\n","Epoch 170/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.5608 - accuracy: 0.4556 - val_loss: 1.5312 - val_accuracy: 0.4663\n","Epoch 171/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.5488 - accuracy: 0.4538 - val_loss: 1.5423 - val_accuracy: 0.5023\n","Epoch 172/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.5377 - accuracy: 0.4631 - val_loss: 1.5299 - val_accuracy: 0.4382\n","Epoch 173/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.5258 - accuracy: 0.4640 - val_loss: 1.4858 - val_accuracy: 0.4677\n","Epoch 174/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.5113 - accuracy: 0.4669 - val_loss: 1.4696 - val_accuracy: 0.4751\n","Epoch 175/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.5069 - accuracy: 0.4661 - val_loss: 1.5793 - val_accuracy: 0.4479\n","Epoch 176/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.5037 - accuracy: 0.4686 - val_loss: 1.4978 - val_accuracy: 0.4411\n","Epoch 177/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.5029 - accuracy: 0.4631 - val_loss: 1.6003 - val_accuracy: 0.3801\n","Epoch 178/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.4820 - accuracy: 0.4714 - val_loss: 1.5761 - val_accuracy: 0.3881\n","Epoch 179/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.4809 - accuracy: 0.4700 - val_loss: 1.4989 - val_accuracy: 0.4240\n","Epoch 180/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.4591 - accuracy: 0.4760 - val_loss: 1.4043 - val_accuracy: 0.5019\n","Epoch 181/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.4605 - accuracy: 0.4756 - val_loss: 1.4146 - val_accuracy: 0.5312\n","Epoch 182/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.4339 - accuracy: 0.4865 - val_loss: 1.3985 - val_accuracy: 0.5327\n","Epoch 183/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.4266 - accuracy: 0.4906 - val_loss: 1.3686 - val_accuracy: 0.5336\n","Epoch 184/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.4400 - accuracy: 0.4790 - val_loss: 1.3662 - val_accuracy: 0.5189\n","Epoch 185/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.4182 - accuracy: 0.4887 - val_loss: 1.4604 - val_accuracy: 0.4759\n","Epoch 186/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.4157 - accuracy: 0.4877 - val_loss: 1.3811 - val_accuracy: 0.4853\n","Epoch 187/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.3880 - accuracy: 0.5021 - val_loss: 1.4047 - val_accuracy: 0.5290\n","Epoch 188/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.4100 - accuracy: 0.4914 - val_loss: 1.3570 - val_accuracy: 0.5570\n","Epoch 189/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.3841 - accuracy: 0.5048 - val_loss: 1.3587 - val_accuracy: 0.5482\n","Epoch 190/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.4012 - accuracy: 0.4985 - val_loss: 1.3122 - val_accuracy: 0.5436\n","Epoch 191/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.3872 - accuracy: 0.5013 - val_loss: 1.3338 - val_accuracy: 0.5082\n","Epoch 192/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.3686 - accuracy: 0.5138 - val_loss: 1.3456 - val_accuracy: 0.5549\n","Epoch 193/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.3561 - accuracy: 0.5172 - val_loss: 1.4152 - val_accuracy: 0.4532\n","Epoch 194/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.3627 - accuracy: 0.5142 - val_loss: 1.5237 - val_accuracy: 0.4285\n","Epoch 195/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.3696 - accuracy: 0.5128 - val_loss: 1.3071 - val_accuracy: 0.5732\n","Epoch 196/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.3706 - accuracy: 0.5095 - val_loss: 1.3213 - val_accuracy: 0.5688\n","Epoch 197/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.3515 - accuracy: 0.5219 - val_loss: 1.2733 - val_accuracy: 0.5735\n","Epoch 198/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.3324 - accuracy: 0.5323 - val_loss: 1.2780 - val_accuracy: 0.5415\n","Epoch 199/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.3170 - accuracy: 0.5393 - val_loss: 1.2580 - val_accuracy: 0.5912\n","Epoch 200/200\n","375/375 [==============================] - 1s 4ms/step - loss: 1.3384 - accuracy: 0.5270 - val_loss: 1.2445 - val_accuracy: 0.5876\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f77ae471ef0>"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PeYbgpQTyoXo","executionInfo":{"status":"ok","timestamp":1606010440487,"user_tz":-540,"elapsed":294519,"user":{"displayName":"박문기(Russell)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizQo6to0OvUtiNQKTVjXpjpc2acrkjL0QP6_B-=s64","userId":"17970950316440342447"}},"outputId":"32fae83d-f9bc-4b75-b335-2ba3875af3a1"},"source":["# 모델 평가\n","test_loss, test_acc = model.evaluate(X_test, Y_test)\n","print(\"Test loss: \", test_loss, \"Test accuracy:\", test_acc)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["313/313 [==============================] - 0s 1ms/step - loss: 11199.0791 - accuracy: 0.4082\n","Test loss:  11199.0791015625 Test accuracy: 0.4081999957561493\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zX9gUPumzVVB","executionInfo":{"status":"ok","timestamp":1606010440496,"user_tz":-540,"elapsed":294517,"user":{"displayName":"박문기(Russell)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizQo6to0OvUtiNQKTVjXpjpc2acrkjL0QP6_B-=s64","userId":"17970950316440342447"}}},"source":["# 모델 저장\n","model.save('mnist_opt_level_01_add_hiddle_layer.h5')"],"execution_count":9,"outputs":[]}]}