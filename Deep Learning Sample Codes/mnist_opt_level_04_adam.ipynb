{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_opt_level_04_adam.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOmIWIUDUNrxdcxVMC8Sowg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkbahk/DeepLearningwithKeras/blob/master/mnist_opt_level_04_adam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLiJzZJNsPOB"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmA6HYaoseKM"
      },
      "source": [
        "#하이퍼 파라메터 정의(매개변수들)\n",
        "EPOCHS = 200\n",
        "BATCH_SIZE = 128\n",
        "VERBOSE = 1\n",
        "NB_CLASSES = 10 #출력갯수 = 숫자의 갯수\n",
        "N_HIDDEN = 128 \n",
        "VALIDATION_SPLIT = 0.2 #검증을 위해 남겨둘 훈련 데이타\n",
        "DROPOUT = 0.3"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a_uWCrqtEIJ",
        "outputId": "1cd91198-dcc2-4a1b-a229-58925c556c46"
      },
      "source": [
        "# MNIST 데이타셋 로드(MNIST는 숫자만, eMNIST는 숫자+알파벳, 패션MNIST는 옷그림들이 있다)\n",
        "# X값 훈련용, 테스트 데이터를 각각 60,000개와 10,000개로 나눈다\n",
        "# 레이블(정답, Y값)에 대한 원핫 인코딩을 자동으로 적용한다\n",
        "# 아래 데이타셋을 .png 형태의 이미지를 이미 숫자화한 배열형태로 바꾸어 놓은 것이며, .csv형태가 분석 초기 데이타이다.\n",
        "mnist = keras.datasets.mnist\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "\n",
        "# X_train은 60,000개 행으로 28x28 값을 가진다. 이를 60,000 x 784(28x28)의 행렬형태로 변환한다.\n",
        "RESHAPED = 784\n",
        "\n",
        "X_train = X_train.reshape(60000, RESHAPED)\n",
        "X_test = X_test.reshape(10000, RESHAPED)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# 입력을 [0, 1] 사이로 정규화\n",
        "X_train /= 255.0\n",
        "X_train /= 255.0\n",
        "\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'train samples')\n",
        "\n",
        "# 레이블을 원한 엔코딩, 그래야 행렬 연산이 가능함\n",
        "Y_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES)\n",
        "Y_test = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000 train samples\n",
            "10000 train samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLoTJoMXvC4S"
      },
      "source": [
        "# 모델 구축(정의)\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(keras.layers.Dense(N_HIDDEN, input_shape=(RESHAPED,), name='input_Dense_layer_1', activation='relu'))\n",
        "model.add(keras.layers.Dropout(DROPOUT))\n",
        "model.add(keras.layers.Dense(N_HIDDEN, name='hidden_Dense_layer_2', activation='relu'))\n",
        "model.add(keras.layers.Dropout(DROPOUT))\n",
        "model.add(keras.layers.Dense(NB_CLASSES, name='output_Dense_layer_3', activation='softmax'))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfRXM9Nhw5Kt"
      },
      "source": [
        "# 모델 컴파일\n",
        "model.compile(optimizer='Adam',\n",
        "             loss='categorical_crossentropy',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsSr7R9RzMFm",
        "outputId": "5a0d7380-8618-4216-f50c-9a2e8a070de5"
      },
      "source": [
        "# 모델 형태 보기\n",
        "model.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_Dense_layer_1 (Dense)  (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "hidden_Dense_layer_2 (Dense) (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "output_Dense_layer_3 (Dense) (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ru4BliBKxrkG",
        "outputId": "ba1aa2b5-eaaa-4fbc-d7fa-1b03f000ddc7"
      },
      "source": [
        "# 모델 훈련\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(patience=15, mode='auto', monitor='val_accuracy')\n",
        "\n",
        "hist = model.fit(x = X_train, y = Y_train, \n",
        "          batch_size = BATCH_SIZE, epochs=EPOCHS,\n",
        "          verbose=VERBOSE, validation_split=VALIDATION_SPLIT,\n",
        "          callbacks=[early_stopping])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.4217 - accuracy: 0.5459 - val_loss: 0.7226 - val_accuracy: 0.7922\n",
            "Epoch 2/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.6919 - accuracy: 0.7804 - val_loss: 0.4675 - val_accuracy: 0.8692\n",
            "Epoch 3/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5255 - accuracy: 0.8439 - val_loss: 0.3745 - val_accuracy: 0.8923\n",
            "Epoch 4/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4442 - accuracy: 0.8704 - val_loss: 0.3247 - val_accuracy: 0.9064\n",
            "Epoch 5/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3980 - accuracy: 0.8817 - val_loss: 0.2916 - val_accuracy: 0.9147\n",
            "Epoch 6/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3614 - accuracy: 0.8934 - val_loss: 0.2653 - val_accuracy: 0.9210\n",
            "Epoch 7/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3308 - accuracy: 0.9020 - val_loss: 0.2418 - val_accuracy: 0.9291\n",
            "Epoch 8/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3100 - accuracy: 0.9085 - val_loss: 0.2238 - val_accuracy: 0.9342\n",
            "Epoch 9/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2854 - accuracy: 0.9156 - val_loss: 0.2127 - val_accuracy: 0.9369\n",
            "Epoch 10/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2719 - accuracy: 0.9183 - val_loss: 0.1973 - val_accuracy: 0.9417\n",
            "Epoch 11/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2549 - accuracy: 0.9243 - val_loss: 0.1876 - val_accuracy: 0.9437\n",
            "Epoch 12/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2399 - accuracy: 0.9289 - val_loss: 0.1780 - val_accuracy: 0.9455\n",
            "Epoch 13/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2315 - accuracy: 0.9310 - val_loss: 0.1658 - val_accuracy: 0.9506\n",
            "Epoch 14/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2192 - accuracy: 0.9355 - val_loss: 0.1603 - val_accuracy: 0.9538\n",
            "Epoch 15/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2086 - accuracy: 0.9386 - val_loss: 0.1524 - val_accuracy: 0.9549\n",
            "Epoch 16/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2007 - accuracy: 0.9396 - val_loss: 0.1452 - val_accuracy: 0.9565\n",
            "Epoch 17/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1953 - accuracy: 0.9425 - val_loss: 0.1402 - val_accuracy: 0.9580\n",
            "Epoch 18/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1865 - accuracy: 0.9440 - val_loss: 0.1376 - val_accuracy: 0.9582\n",
            "Epoch 19/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1812 - accuracy: 0.9460 - val_loss: 0.1343 - val_accuracy: 0.9590\n",
            "Epoch 20/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1736 - accuracy: 0.9482 - val_loss: 0.1289 - val_accuracy: 0.9614\n",
            "Epoch 21/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1658 - accuracy: 0.9510 - val_loss: 0.1248 - val_accuracy: 0.9632\n",
            "Epoch 22/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1600 - accuracy: 0.9512 - val_loss: 0.1247 - val_accuracy: 0.9626\n",
            "Epoch 23/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1573 - accuracy: 0.9521 - val_loss: 0.1195 - val_accuracy: 0.9638\n",
            "Epoch 24/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1522 - accuracy: 0.9535 - val_loss: 0.1169 - val_accuracy: 0.9639\n",
            "Epoch 25/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1501 - accuracy: 0.9546 - val_loss: 0.1151 - val_accuracy: 0.9646\n",
            "Epoch 26/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1461 - accuracy: 0.9554 - val_loss: 0.1121 - val_accuracy: 0.9663\n",
            "Epoch 27/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1413 - accuracy: 0.9567 - val_loss: 0.1094 - val_accuracy: 0.9676\n",
            "Epoch 28/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1387 - accuracy: 0.9586 - val_loss: 0.1105 - val_accuracy: 0.9670\n",
            "Epoch 29/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1303 - accuracy: 0.9605 - val_loss: 0.1062 - val_accuracy: 0.9691\n",
            "Epoch 30/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1335 - accuracy: 0.9589 - val_loss: 0.1022 - val_accuracy: 0.9705\n",
            "Epoch 31/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1270 - accuracy: 0.9624 - val_loss: 0.1037 - val_accuracy: 0.9686\n",
            "Epoch 32/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1276 - accuracy: 0.9614 - val_loss: 0.1059 - val_accuracy: 0.9692\n",
            "Epoch 33/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1229 - accuracy: 0.9620 - val_loss: 0.0998 - val_accuracy: 0.9712\n",
            "Epoch 34/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1203 - accuracy: 0.9641 - val_loss: 0.1002 - val_accuracy: 0.9712\n",
            "Epoch 35/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1174 - accuracy: 0.9648 - val_loss: 0.0986 - val_accuracy: 0.9722\n",
            "Epoch 36/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1135 - accuracy: 0.9656 - val_loss: 0.0991 - val_accuracy: 0.9712\n",
            "Epoch 37/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1127 - accuracy: 0.9653 - val_loss: 0.0954 - val_accuracy: 0.9728\n",
            "Epoch 38/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1110 - accuracy: 0.9658 - val_loss: 0.0966 - val_accuracy: 0.9724\n",
            "Epoch 39/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1080 - accuracy: 0.9665 - val_loss: 0.0971 - val_accuracy: 0.9711\n",
            "Epoch 40/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1080 - accuracy: 0.9661 - val_loss: 0.0964 - val_accuracy: 0.9717\n",
            "Epoch 41/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1032 - accuracy: 0.9681 - val_loss: 0.0939 - val_accuracy: 0.9723\n",
            "Epoch 42/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1043 - accuracy: 0.9671 - val_loss: 0.0941 - val_accuracy: 0.9741\n",
            "Epoch 43/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0982 - accuracy: 0.9696 - val_loss: 0.0942 - val_accuracy: 0.9737\n",
            "Epoch 44/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0995 - accuracy: 0.9694 - val_loss: 0.0925 - val_accuracy: 0.9726\n",
            "Epoch 45/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0982 - accuracy: 0.9688 - val_loss: 0.0912 - val_accuracy: 0.9747\n",
            "Epoch 46/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0964 - accuracy: 0.9703 - val_loss: 0.0875 - val_accuracy: 0.9749\n",
            "Epoch 47/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0966 - accuracy: 0.9698 - val_loss: 0.0887 - val_accuracy: 0.9746\n",
            "Epoch 48/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0939 - accuracy: 0.9718 - val_loss: 0.0910 - val_accuracy: 0.9728\n",
            "Epoch 49/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0934 - accuracy: 0.9704 - val_loss: 0.0891 - val_accuracy: 0.9738\n",
            "Epoch 50/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0895 - accuracy: 0.9720 - val_loss: 0.0883 - val_accuracy: 0.9739\n",
            "Epoch 51/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0900 - accuracy: 0.9730 - val_loss: 0.0915 - val_accuracy: 0.9748\n",
            "Epoch 52/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0883 - accuracy: 0.9724 - val_loss: 0.0907 - val_accuracy: 0.9747\n",
            "Epoch 53/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0867 - accuracy: 0.9734 - val_loss: 0.0877 - val_accuracy: 0.9755\n",
            "Epoch 54/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0878 - accuracy: 0.9725 - val_loss: 0.0877 - val_accuracy: 0.9748\n",
            "Epoch 55/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0845 - accuracy: 0.9733 - val_loss: 0.0875 - val_accuracy: 0.9753\n",
            "Epoch 56/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0840 - accuracy: 0.9738 - val_loss: 0.0875 - val_accuracy: 0.9759\n",
            "Epoch 57/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0822 - accuracy: 0.9744 - val_loss: 0.0880 - val_accuracy: 0.9748\n",
            "Epoch 58/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0821 - accuracy: 0.9737 - val_loss: 0.0891 - val_accuracy: 0.9749\n",
            "Epoch 59/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0816 - accuracy: 0.9744 - val_loss: 0.0883 - val_accuracy: 0.9753\n",
            "Epoch 60/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0793 - accuracy: 0.9744 - val_loss: 0.0835 - val_accuracy: 0.9767\n",
            "Epoch 61/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0795 - accuracy: 0.9757 - val_loss: 0.0847 - val_accuracy: 0.9753\n",
            "Epoch 62/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0777 - accuracy: 0.9751 - val_loss: 0.0873 - val_accuracy: 0.9752\n",
            "Epoch 63/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0773 - accuracy: 0.9755 - val_loss: 0.0868 - val_accuracy: 0.9760\n",
            "Epoch 64/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0760 - accuracy: 0.9762 - val_loss: 0.0861 - val_accuracy: 0.9760\n",
            "Epoch 65/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0740 - accuracy: 0.9763 - val_loss: 0.0840 - val_accuracy: 0.9766\n",
            "Epoch 66/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0736 - accuracy: 0.9764 - val_loss: 0.0868 - val_accuracy: 0.9761\n",
            "Epoch 67/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0745 - accuracy: 0.9763 - val_loss: 0.0832 - val_accuracy: 0.9767\n",
            "Epoch 68/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0734 - accuracy: 0.9768 - val_loss: 0.0857 - val_accuracy: 0.9761\n",
            "Epoch 69/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0707 - accuracy: 0.9776 - val_loss: 0.0876 - val_accuracy: 0.9757\n",
            "Epoch 70/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0707 - accuracy: 0.9772 - val_loss: 0.0861 - val_accuracy: 0.9761\n",
            "Epoch 71/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0710 - accuracy: 0.9764 - val_loss: 0.0875 - val_accuracy: 0.9760\n",
            "Epoch 72/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0722 - accuracy: 0.9765 - val_loss: 0.0883 - val_accuracy: 0.9762\n",
            "Epoch 73/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0675 - accuracy: 0.9778 - val_loss: 0.0834 - val_accuracy: 0.9763\n",
            "Epoch 74/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0697 - accuracy: 0.9774 - val_loss: 0.0855 - val_accuracy: 0.9773\n",
            "Epoch 75/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0667 - accuracy: 0.9781 - val_loss: 0.0913 - val_accuracy: 0.9758\n",
            "Epoch 76/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0657 - accuracy: 0.9781 - val_loss: 0.0861 - val_accuracy: 0.9764\n",
            "Epoch 77/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0671 - accuracy: 0.9784 - val_loss: 0.0846 - val_accuracy: 0.9770\n",
            "Epoch 78/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0621 - accuracy: 0.9801 - val_loss: 0.0856 - val_accuracy: 0.9763\n",
            "Epoch 79/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0645 - accuracy: 0.9787 - val_loss: 0.0856 - val_accuracy: 0.9762\n",
            "Epoch 80/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0658 - accuracy: 0.9784 - val_loss: 0.0855 - val_accuracy: 0.9774\n",
            "Epoch 81/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0673 - accuracy: 0.9787 - val_loss: 0.0871 - val_accuracy: 0.9768\n",
            "Epoch 82/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0625 - accuracy: 0.9800 - val_loss: 0.0854 - val_accuracy: 0.9752\n",
            "Epoch 83/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0620 - accuracy: 0.9799 - val_loss: 0.0850 - val_accuracy: 0.9765\n",
            "Epoch 84/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0601 - accuracy: 0.9799 - val_loss: 0.0869 - val_accuracy: 0.9760\n",
            "Epoch 85/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0594 - accuracy: 0.9805 - val_loss: 0.0838 - val_accuracy: 0.9762\n",
            "Epoch 86/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0607 - accuracy: 0.9800 - val_loss: 0.0906 - val_accuracy: 0.9757\n",
            "Epoch 87/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0600 - accuracy: 0.9797 - val_loss: 0.0848 - val_accuracy: 0.9767\n",
            "Epoch 88/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0594 - accuracy: 0.9815 - val_loss: 0.0870 - val_accuracy: 0.9763\n",
            "Epoch 89/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0591 - accuracy: 0.9802 - val_loss: 0.0852 - val_accuracy: 0.9780\n",
            "Epoch 90/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0601 - accuracy: 0.9806 - val_loss: 0.0852 - val_accuracy: 0.9758\n",
            "Epoch 91/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0575 - accuracy: 0.9814 - val_loss: 0.0867 - val_accuracy: 0.9771\n",
            "Epoch 92/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0565 - accuracy: 0.9816 - val_loss: 0.0859 - val_accuracy: 0.9769\n",
            "Epoch 93/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0579 - accuracy: 0.9810 - val_loss: 0.0866 - val_accuracy: 0.9771\n",
            "Epoch 94/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0575 - accuracy: 0.9812 - val_loss: 0.0867 - val_accuracy: 0.9772\n",
            "Epoch 95/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0577 - accuracy: 0.9814 - val_loss: 0.0871 - val_accuracy: 0.9769\n",
            "Epoch 96/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0568 - accuracy: 0.9815 - val_loss: 0.0879 - val_accuracy: 0.9764\n",
            "Epoch 97/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0540 - accuracy: 0.9821 - val_loss: 0.0868 - val_accuracy: 0.9768\n",
            "Epoch 98/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0575 - accuracy: 0.9815 - val_loss: 0.0861 - val_accuracy: 0.9766\n",
            "Epoch 99/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0552 - accuracy: 0.9816 - val_loss: 0.0849 - val_accuracy: 0.9773\n",
            "Epoch 100/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0562 - accuracy: 0.9822 - val_loss: 0.0856 - val_accuracy: 0.9771\n",
            "Epoch 101/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0530 - accuracy: 0.9835 - val_loss: 0.0909 - val_accuracy: 0.9768\n",
            "Epoch 102/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0543 - accuracy: 0.9818 - val_loss: 0.0897 - val_accuracy: 0.9769\n",
            "Epoch 103/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0527 - accuracy: 0.9827 - val_loss: 0.0891 - val_accuracy: 0.9767\n",
            "Epoch 104/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0526 - accuracy: 0.9830 - val_loss: 0.0882 - val_accuracy: 0.9765\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeYbgpQTyoXo",
        "outputId": "56dcf213-3938-417a-9835-5cd91dcd7ed2"
      },
      "source": [
        "# 모델 평가\n",
        "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
        "print(\"Test loss: \", round(test_loss,4), \"Test accuracy:\", round(test_acc,4))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 4745.9902 - accuracy: 0.9661\n",
            "Test loss:  4745.9902 Test accuracy: 0.9661\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX9gUPumzVVB"
      },
      "source": [
        "# 모델 저장\n",
        "model.save('mnist_opt_level_04_Adam.h5')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "1b4NPyHk5M1P",
        "outputId": "1a1c5bff-cd30-448a-d175-75789fae17f2"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, loss_ax =  plt.subplots()\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
        "#loss_ax.plot(hist.history['val_loss'], 'g', label='validation loss')\n",
        "acc_ax.plot(hist.history['accuracy'], 'b', label='train accuracy')\n",
        "#acc_ax.plot(hist.history['val_accuracy'], 'r', label='validation accuracy')\n",
        "\n",
        "plt.legend(['train loss', 'train accuracy'])\n",
        "plt.show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}