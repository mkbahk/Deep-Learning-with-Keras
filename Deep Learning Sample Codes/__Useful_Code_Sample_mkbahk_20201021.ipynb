{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "__Useful-Code-Sample-mkbahk-20201021.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPcfJYFWSmuo6YEqYOwkrbo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkbahk/DeepLearningwithKeras/blob/master/__Useful_Code_Sample_mkbahk_20201021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sW0TTIHaoeS"
      },
      "source": [
        "EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5IvpwttafGs"
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(patience=15, mode='auto', monitor='val_acc')\n",
        "hist = model.fit_generator(train_generator,\n",
        "                           steps_per_epoch=train_generator.samples // batch_size,\n",
        "                           validation_data = validation_generator,\n",
        "                           epochs=100,\n",
        "                           callbacks=[early_stopping]\n",
        "                           )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3EBO2Ooa3If"
      },
      "source": [
        "훈련 및 평가 그래프 그리기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1iuoPHga21O"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, loss_ax =  plt.subplots()\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
        "loss_ax.plot(hist.history['val_loss'], 'g', label='validation loss')\n",
        "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
        "acc_ax.plot(hist.history['val_acc'], 'r', label='validation acc')\n",
        "\n",
        "plt.legend(['train acc', 'validation acc'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o23A3WS9auFO"
      },
      "source": [
        "Tensorboard\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHiHgtEdax57"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os as os\n",
        "from tensorflow import keras\n",
        "from datetime import datetime\n",
        "\n",
        "!rm -rf ./logs/ #to delete previous runs\n",
        "%load_ext tensorboard\n",
        "logdir = os.path.join(\"logs\", datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "#%tensorboard --logdir logs\n",
        "\n",
        "\n",
        "\n",
        "#예측과 검증이 끝난 후에 아래 코드 삽입\n",
        "%tensorboard --logdir logs\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EIwfwJ8dRNg"
      },
      "source": [
        "모델 저장하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21pIuTFMdTL4"
      },
      "source": [
        "model.save('cats_and_dogs_small_1.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuhLWgbSdjVx"
      },
      "source": [
        "훈련 시간 측정\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moCjR5D9dleE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "724f0e29-aba2-4a3e-8f3c-1f34aca9529e"
      },
      "source": [
        "import time\n",
        "import os\n",
        "\n",
        "start = time.time() # 시작 시간 저장\n",
        "\n",
        "\n",
        "print(\"실행시간 :\", time.time() - start,\"(초)\")  # 현재시각 - 시작시간 = 실행 시간\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "실행시간 : 2.288818359375e-05 (초)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfLh7i7peRwb"
      },
      "source": [
        "TPU 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ko0309BBeT75"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "import time\n",
        "import os\n",
        "\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "print(tf.config.list_physical_devices(\"CPU\"))\n",
        "print(tf.config.list_physical_devices(\"GPU\"))\n",
        "\n",
        "\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://'+os.environ['COLAB_TPU_ADDR'])\n",
        "#Connect to the TPU handle and initialise it\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "strategy = tf.distribute.TPUStrategy(resolver)\n",
        "\n",
        "\n",
        "# Create the model using the IPU-specific Sequential class instead of the\n",
        "# standard tf.keras.Sequential class\n",
        "def create_model():\n",
        "    model = tf.keras.Sequential([\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(128, activation='relu'),\n",
        "        keras.layers.Dense(256, activation='relu'),\n",
        "        keras.layers.Dense(128, activation='relu'),\n",
        "        keras.layers.Dense(10, activation='softmax')])\n",
        "    \n",
        "    model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(), \n",
        "                  optimizer = tf.keras.optimizers.Adam(), \n",
        "                  experimental_steps_per_execution = 50, \n",
        "                  metrics=['sparse_categorical_accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "      # Get the training dataset.\n",
        "      print(\"==============================Getting Training DataSet==============================\\n\\n\")\n",
        "      ds1 = create_train_dataset()\n",
        "      print(\"==============================Getting Test DataSet==============================\\n\\n\")\n",
        "      ds2 = create_test_dataset()\n",
        "\n",
        "      with strategy.scope():   \n",
        "        # Create an instance of the model.\n",
        "        print(\"==============================Building Model & Compile ==============================\\n\\n\")\n",
        "        model = create_model()\n",
        "      #end of with"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8z-18cmeiZ5"
      },
      "source": [
        "GPU 분산전략"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jq1btp0ex8I"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import time, os\n",
        "\n",
        "# Create a MirroredStrategy.\n",
        "print(tf.config.list_physical_devices(\"CPU\"))\n",
        "print(tf.config.list_physical_devices(\"GPU\"))\n",
        "gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
        "\n",
        "if len(gpus) > 1:\n",
        "  strategy = tf.distribute.MirroredStrategy([gpu.name for gpu in gpus])\n",
        "  print('\\n\\nRunning on multiple GPUs ', [gpu.name for gpu in gpus])\n",
        "elif len(gpus) == 1:\n",
        "  strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "  print('\\n\\nRunning on single GPU ', gpus[0].name)\n",
        "else:\n",
        "  strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "  print(\"'\\n\\nRunning on CPU '\")\n",
        "#end of if\n",
        " \n",
        "print(\"Number of devices: {}\".format(strategy.num_replicas_in_sync))\n",
        "\n",
        "# Open a strategy scope.\n",
        "with strategy.scope():\n",
        "    # Everything that creates variables should be under the strategy scope.\n",
        "    # In general this is only model construction & `compile()`.\n",
        "    model = get_compiled_model()\n",
        "\n",
        "# Train the model on all available devices.\n",
        "train_dataset, val_dataset, test_dataset = get_dataset()\n",
        "model.fit(train_dataset, epochs=10, validation_data=val_dataset)\n",
        "\n",
        "# Test the model on all available devices.\n",
        "model.evaluate(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wFgA8Kte0CD"
      },
      "source": [
        "CPU 분산전략"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHtuzRh3eziY"
      },
      "source": [
        "  strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "  print(\"'\\n\\nRunning on CPU '\")\n",
        "#end of if\n",
        " \n",
        "print(\"Number of devices: {}\".format(strategy.num_replicas_in_sync))\n",
        "\n",
        "# Open a strategy scope.\n",
        "with strategy.scope():\n",
        "    # Everything that creates variables should be under the strategy scope.\n",
        "    # In general this is only model construction & `compile()`.\n",
        "    model = get_compiled_model()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MjLVhEffCXO"
      },
      "source": [
        "IPU 분산전략"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcZ3HAO5fElx"
      },
      "source": [
        "from tensorflow.python import ipu\n",
        "print(tf.config.list_physical_devices(\"IPU\"), \"\\n\\n\")\n",
        "\n",
        "# Configure the IPU system\n",
        "cfg = ipu.utils.create_ipu_config()\n",
        "cfg = ipu.utils.auto_select_ipus(cfg, 2)\n",
        "ipu.utils.configure_ipu_system(cfg)\n",
        "\n",
        "\n",
        "\n",
        "strategy = ipu.ipu_strategy.IPUStrategy()\n",
        "   with strategy.scope():\n",
        "      model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(), optimizer = tf.keras.optimizers.Adam(),  metrics=['sparse_categorical_accuracy'])\n",
        "      model.fit(ds1, steps_per_epoch=2000, epochs=50)\n",
        "\n",
        "      print(\"\\n\\n==============================Checking the result==============================\\n\\n\")\n",
        "      (loss, accuracy) = model.evaluate(ds2, steps=1000)\n",
        "      print(\"Validation loss: {}\".format(loss))\n",
        "      print(\"Validation accuracy: {}%\".format(100.0 * accuracy))\n",
        "      print(\"\\n\\n==============================Job Done by Graphcore IPU with 16 Sockets, 19,456 Cores!!!==============================\")\n",
        "   #end of with:\n",
        "#end of def"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0PIbczUfdLf"
      },
      "source": [
        "이미지 보여주기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLSBW-2ffgM9"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(int(labels[i]))\n",
        "        plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Or_ZQvWrwBiS"
      },
      "source": [
        "Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCJZVtYOwgu0"
      },
      "source": [
        "predictions = model.predict(x=scaled_test_samples, batch_size=10, verbose=0) \n",
        "rounded_predictions = model.predict_classes(scaled_test_samples, batch_size=10, verbose=0) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UL8Y4RFv9Mf"
      },
      "source": [
        "%matplotlib inline\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwDGLx80wHDa"
      },
      "source": [
        "cm = confusion_matrix(test_labels, rounded_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6j4JDWwwwJvj"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBLX_MjbwPmK"
      },
      "source": [
        "cm_plot_labels = ['no_side_effects','had_side_effects']\n",
        "plot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}