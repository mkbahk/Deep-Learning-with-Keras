{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"5-2 Cat and Dog DatsSet Download and unzipping.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNOrytJZhXFm+2Lx3VinkJM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"suyPxcH5PPJF"},"source":["캐글에서 다운받아 colab에 업로드시 너무 오래걸려 googleapis에서 다운받음"]},{"cell_type":"code","metadata":{"id":"YYXu-iW0h6PB","executionInfo":{"status":"ok","timestamp":1601801220075,"user_tz":-540,"elapsed":1949,"user":{"displayName":"박문기(Russell)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizQo6to0OvUtiNQKTVjXpjpc2acrkjL0QP6_B-=s64","userId":"17970950316440342447"}}},"source":["import os, shutil, zipfile\n","from keras import models, layers, optimizers"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"3sd9dQWa23aj","executionInfo":{"status":"ok","timestamp":1601801236808,"user_tz":-540,"elapsed":18659,"user":{"displayName":"박문기(Russell)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizQo6to0OvUtiNQKTVjXpjpc2acrkjL0QP6_B-=s64","userId":"17970950316440342447"}},"outputId":"35f5de4e-2f01-436f-c63e-cea24ff228aa","colab":{"base_uri":"https://localhost:8080/","height":233}},"source":["# If the URL doesn't work, visit https://www.microsoft.com/en-us/download/confirmation.aspx?id=54765\n","# And right click on the 'Download Manually' link to get a new URL to the dataset\n","\n","# Note: This is a very large dataset and will take time to download\n","!mkdir /tmp\n","!wget --no-check-certificate \\\n","    \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\" \\\n","    -O \"/tmp/cats-and-dogs.zip\"\n","\n","local_zip = '/tmp/cats-and-dogs.zip'\n","zip_ref   = zipfile.ZipFile(local_zip, 'r')\n","zip_ref.extractall('/tmp')\n","zip_ref.close()\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["mkdir: cannot create directory ‘/tmp’: File exists\n","--2020-10-04 08:46:59--  https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\n","Resolving download.microsoft.com (download.microsoft.com)... 173.222.113.209, 2600:1402:2000:193::e59, 2600:1402:2000:1bb::e59\n","Connecting to download.microsoft.com (download.microsoft.com)|173.222.113.209|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 824894548 (787M) [application/octet-stream]\n","Saving to: ‘/tmp/cats-and-dogs.zip’\n","\n","/tmp/cats-and-dogs. 100%[===================>] 786.68M   105MB/s    in 8.1s    \n","\n","2020-10-04 08:47:08 (97.1 MB/s) - ‘/tmp/cats-and-dogs.zip’ saved [824894548/824894548]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cGa5d-gtPt7i"},"source":["훈련, 검증, 테스트 폴더로 이미지 복사하기"]},{"cell_type":"code","metadata":{"id":"-X3F0_AKPzja","executionInfo":{"status":"ok","timestamp":1601801236813,"user_tz":-540,"elapsed":18640,"user":{"displayName":"박문기(Russell)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizQo6to0OvUtiNQKTVjXpjpc2acrkjL0QP6_B-=s64","userId":"17970950316440342447"}}},"source":["original_dataset_dir ='/tmp/PetImages'  # 원본 데이터셋을 압축 해제한 디렉토리 경로\n","base_dir = '/tmp/cats_and_dogs_small' #소규모 데이타셋을 저장할 디렉토리\n","\n","if not os.path.isdir(base_dir):\n","  os.mkdir(base_dir)\n","#end of if\n","\n","#훈련, 검증, 테스트 분할을 위한 디렉토리\n","train_dir = os.path.join(base_dir, 'train')\n","os.mkdir(train_dir)\n","validation_dir = os.path.join(base_dir, 'validation')\n","os.mkdir(validation_dir)\n","test_dir = os.path.join(base_dir, 'test')\n","os.mkdir(test_dir)\n","\n","#훈련용 고양이 사진 디렉토리\n","train_cats_dir = os.path.join(train_dir, 'cats')\n","os.mkdir(train_cats_dir)\n","\n","#훈련용 강아지 사진 디렉토리\n","train_dogs_dir = os.path.join(train_dir, 'dogs')\n","os.mkdir(train_dogs_dir)\n","\n","#검증용 고양이 사진 디렉토리\n","validation_cats_dir = os.path.join(validation_dir, 'cats')\n","os.mkdir(validation_cats_dir)\n","\n","#검증용 강아지 사진 디렉토리\n","validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n","os.mkdir(validation_dogs_dir)\n","\n","#테스트용 고양이 사진 디렉토리\n","test_cats_dir = os.path.join(test_dir, 'cats')\n","os.mkdir(test_cats_dir)\n","\n","#테스트용 강아지 사진 디렉토리\n","test_dogs_dir = os.path.join(test_dir, 'dogs')\n","os.mkdir(test_dogs_dir)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"_M_T_pgqZjaj","executionInfo":{"status":"ok","timestamp":1601801237406,"user_tz":-540,"elapsed":19222,"user":{"displayName":"박문기(Russell)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizQo6to0OvUtiNQKTVjXpjpc2acrkjL0QP6_B-=s64","userId":"17970950316440342447"}}},"source":["#처음 1,000개의 고양이 이미지를 train_cats_dir에 복사한다.\n","fnames = ['{}.jpg'.format(i) for i in range(1000)]\n","for fname in fnames:\n","  src = os.path.join(original_dataset_dir+\"/Cat\", fname)\n","  dst = os.path.join(train_cats_dir, fname)\n","  shutil.copy(src, dst)\n","#end of for\n","\n","#다음 500개의 고양이 이미지를 validation_cats_dir에 복사한다.\n","fnames = ['{}.jpg'.format(i) for i in range(1000, 1500)]\n","for fname in fnames:\n","  src = os.path.join(original_dataset_dir+\"/Cat\", fname)\n","  dst = os.path.join(validation_cats_dir, fname)\n","  shutil.copy(src, dst)\n","#end of fo\n","\n","#다음음 500개의 고양이 이미지를 test_cats_dir에 복사한다.\n","fnames = ['{}.jpg'.format(i) for i in range(1500, 2000)]\n","for fname in fnames:\n","  src = os.path.join(original_dataset_dir+\"/Cat\", fname)\n","  dst = os.path.join(test_cats_dir, fname)\n","  shutil.copy(src, dst)\n","#end of for\n","\n","\n","#처음 1,000개의 강아지 이미지를 train_dogs_dir에 복사한다.\n","fnames = ['{}.jpg'.format(i) for i in range(1000)]\n","for fname in fnames:\n","  src = os.path.join(original_dataset_dir+\"/Dog\", fname)\n","  dst = os.path.join(train_dogs_dir, fname)\n","  shutil.copy(src, dst)\n","#end of for\n","\n","#다음 500개의 강아지 이미지를 validation_dogs_dir에 복사한다.\n","fnames = ['{}.jpg'.format(i) for i in range(1000, 1500)]\n","for fname in fnames:\n","  src = os.path.join(original_dataset_dir+\"/Dog\", fname)\n","  dst = os.path.join(validation_dogs_dir, fname)\n","  shutil.copy(src, dst)\n","#end of for\n","\n","#다음음 500개의 강아지 이미지를 test_dogs_dir에 복사한다.\n","fnames = ['{}.jpg'.format(i) for i in range(1500, 2000)]\n","for fname in fnames:\n","  src = os.path.join(original_dataset_dir+\"/Dog\", fname)\n","  dst = os.path.join(test_dogs_dir, fname)\n","  shutil.copy(src, dst)\n","#end of for"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RG9Hz3a9mAuq"},"source":["정상복사를 확인하기 위해 각 분할(훈련/검증/테스트)에 들어 있는 사진의 개수를 카운트"]},{"cell_type":"code","metadata":{"id":"BIiqYwV8mLp1","executionInfo":{"status":"ok","timestamp":1601801237412,"user_tz":-540,"elapsed":19206,"user":{"displayName":"박문기(Russell)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizQo6to0OvUtiNQKTVjXpjpc2acrkjL0QP6_B-=s64","userId":"17970950316440342447"}},"outputId":"ef9bc7f4-b39e-46a9-e45e-c58ef678a4a8","colab":{"base_uri":"https://localhost:8080/","height":305}},"source":["print(\"원본 고양이 이미지 전체 개수\", len(os.listdir(original_dataset_dir+\"/Cat\")))\n","print(\"원본 강아지 이미지 전체 개수\", len(os.listdir(original_dataset_dir+\"/Dog\")))\n","print(\"\\n\")\n","print(\"훈련용 고양이 이미지 전체 개수\", len(os.listdir(train_cats_dir)))\n","print(\"훈련용 강아지 이미지 전체 개수\", len(os.listdir(train_dogs_dir)))\n","print(\"\\n\")\n","print(\"검증용 고양이 이미지 전체 개수\", len(os.listdir(validation_cats_dir)))\n","print(\"검증용 강아지 이미지 전체 개수\", len(os.listdir(validation_dogs_dir)))\n","print(\"\\n\")\n","print(\"테스트용 고양이 이미지 전체 개수\", len(os.listdir(test_cats_dir)))\n","print(\"테스트용 강아지 이미지 전체 개수\", len(os.listdir(test_dogs_dir)))\n","print(\"\\n\")"],"execution_count":5,"outputs":[{"output_type":"stream","text":["원본 고양이 이미지 전체 개수 12501\n","원본 강아지 이미지 전체 개수 12501\n","\n","\n","훈련용 고양이 이미지 전체 개수 1000\n","훈련용 강아지 이미지 전체 개수 1000\n","\n","\n","검증용 고양이 이미지 전체 개수 500\n","검증용 강아지 이미지 전체 개수 500\n","\n","\n","테스트용 고양이 이미지 전체 개수 500\n","테스트용 강아지 이미지 전체 개수 500\n","\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qw5iS7yjo2om"},"source":["고양이와 강아지를 분류를 위한 초규모 컨브넷 만들기"]},{"cell_type":"code","metadata":{"id":"ZHIBObBQo924","executionInfo":{"status":"ok","timestamp":1601801247068,"user_tz":-540,"elapsed":28841,"user":{"displayName":"박문기(Russell)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizQo6to0OvUtiNQKTVjXpjpc2acrkjL0QP6_B-=s64","userId":"17970950316440342447"}},"outputId":"66f2ad85-ae24-478a-89f3-1bc8a11f2632","colab":{"base_uri":"https://localhost:8080/","height":557}},"source":["model = models.Sequential()\n","model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150,3)))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Flatten())\n","model.add(layers.Dense(512, activation='relu'))\n","model.add(layers.Dense(1, activation='sigmoid'))\n","model.summary()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 148, 148, 32)      896       \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 74, 74, 32)        0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 72, 72, 64)        18496     \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 34, 34, 128)       73856     \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 17, 17, 128)       0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 15, 15, 128)       147584    \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 7, 7, 128)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 6272)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 512)               3211776   \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1)                 513       \n","=================================================================\n","Total params: 3,453,121\n","Trainable params: 3,453,121\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8wrvu8nzsERi"},"source":["모델 컴파일"]},{"cell_type":"code","metadata":{"id":"8AEtdBhlsG_x","executionInfo":{"status":"ok","timestamp":1601801247074,"user_tz":-540,"elapsed":28822,"user":{"displayName":"박문기(Russell)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizQo6to0OvUtiNQKTVjXpjpc2acrkjL0QP6_B-=s64","userId":"17970950316440342447"}}},"source":["model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4), metrics=['acc'])"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EUWZzOZ5txts"},"source":["데이타 전처리: ImageDataGenerator를 사용하여 디렉토리에서 이미지 읽기"]},{"cell_type":"code","metadata":{"id":"-Fo8YwYCt6iG","executionInfo":{"status":"ok","timestamp":1601801247075,"user_tz":-540,"elapsed":28786,"user":{"displayName":"박문기(Russell)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizQo6to0OvUtiNQKTVjXpjpc2acrkjL0QP6_B-=s64","userId":"17970950316440342447"}},"outputId":"ecd05726-e16b-409a-dd2e-41a5737b935a","colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["from keras.preprocessing.image import ImageDataGenerator\n","\n","#모든 이미지를 1/255로 스케일을 조정한다.\n","train_datagen =  ImageDataGenerator(rescale=1./255)\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    train_dir, #타깃 디렉토리\n","    target_size=(150,150), #모든 이미지를 150x150 크기로 바꿉니다.\n","    batch_size = 20, \n","    class_mode = 'binary' )  #binary_crossentropy 손실을 사용하기 때문에 이진 레이블을 필요합니다.\n","validation_generator = test_datagen.flow_from_directory(\n","    validation_dir,\n","    target_size=(150, 150),\n","    batch_size=20,\n","    class_mode='binary')"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Found 2000 images belonging to 2 classes.\n","Found 1000 images belonging to 2 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"is3JTwX8zPxF","executionInfo":{"status":"ok","timestamp":1601801363211,"user_tz":-540,"elapsed":660,"user":{"displayName":"박문기(Russell)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizQo6to0OvUtiNQKTVjXpjpc2acrkjL0QP6_B-=s64","userId":"17970950316440342447"}},"outputId":"e7008976-c95f-4432-c299-596acabe75a0","colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["for data_batch, labels_batch in train_generator:\n","    print('배치 데이터 크기:', data_batch.shape)\n","    print('배치 레이블 크기:', labels_batch.shape)\n","    break"],"execution_count":10,"outputs":[{"output_type":"stream","text":["배치 데이터 크기: (20, 150, 150, 3)\n","배치 레이블 크기: (20,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bIgzLUltxEzg"},"source":["배치 제너레이터를 사용하여 모델 훈련하기"]},{"cell_type":"code","metadata":{"id":"llKnN5dUxJMs","executionInfo":{"status":"error","timestamp":1601801375372,"user_tz":-540,"elapsed":6758,"user":{"displayName":"박문기(Russell)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizQo6to0OvUtiNQKTVjXpjpc2acrkjL0QP6_B-=s64","userId":"17970950316440342447"}},"outputId":"e78c9d9b-b530-46b9-9024-940465fffcf5","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["history =  model.fit_generator(\n","    train_generator,\n","    steps_per_epoch=100,\n","    epochs=30,\n","    validation_data=validation_generator, \n","    validation_steps=50)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n"," 94/100 [===========================>..] - ETA: 0s - loss: 0.6873 - acc: 0.5479"],"name":"stdout"},{"output_type":"error","ename":"UnknownError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-a939218aec5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     validation_steps=50)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1827\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1829\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m   @deprecation.deprecated(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnknownError\u001b[0m: 2 root error(s) found.\n  (0) Unknown:  UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbadb746af0>\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 244, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\", line 302, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 827, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\", line 814, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\", line 940, in generator_fn\n    yield x[i]\n\n  File \"/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py\", line 230, in _get_batches_of_transformed_samples\n    interpolation=self.interpolation)\n\n  File \"/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py\", line 114, in load_img\n    img = pil_image.open(io.BytesIO(f.read()))\n\n  File \"/usr/local/lib/python3.6/dist-packages/PIL/Image.py\", line 2862, in open\n    \"cannot identify image file %r\" % (filename if filename else fp)\n\nPIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbadb746af0>\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_7]]\n  (1) Unknown:  UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbadb746af0>\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 244, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\", line 302, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 827, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\", line 814, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\", line 940, in generator_fn\n    yield x[i]\n\n  File \"/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py\", line 230, in _get_batches_of_transformed_samples\n    interpolation=self.interpolation)\n\n  File \"/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py\", line 114, in load_img\n    img = pil_image.open(io.BytesIO(f.read()))\n\n  File \"/usr/local/lib/python3.6/dist-packages/PIL/Image.py\", line 2862, in open\n    \"cannot identify image file %r\" % (filename if filename else fp)\n\nPIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbadb746af0>\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_1204]\n\nFunction call stack:\ntrain_function -> train_function\n"]}]},{"cell_type":"markdown","metadata":{"id":"AGqLabrJxvDi"},"source":["모델 저장하기"]},{"cell_type":"code","metadata":{"id":"hk8OuSOUxxWo","executionInfo":{"status":"aborted","timestamp":1601801256309,"user_tz":-540,"elapsed":37995,"user":{"displayName":"박문기(Russell)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizQo6to0OvUtiNQKTVjXpjpc2acrkjL0QP6_B-=s64","userId":"17970950316440342447"}}},"source":["model.save('cats_and_dogs_small_1.h5')"],"execution_count":null,"outputs":[]}]}